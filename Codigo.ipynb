{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daee9c85",
   "metadata": {},
   "source": [
    "Proyecto 2 - probabilidad y estadistica \n",
    "\n",
    "- Miguel Angel Nava Perez\n",
    "- Ana Luisa Parra Valencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b53a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats \n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp \n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm \n",
    "from tabulate import tabulate\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "\n",
    "def test_normalityKS(data, variable): # Pruaba de Normalidad Kolmogorov-Smirnof \n",
    "    \"\"\"\n",
    "    data: arreglo de datos a evaluar la normalidad\n",
    "    variable: string con el nombre de la variable \n",
    "    \"\"\"  \n",
    "    print(f\"\\n Análisis de normalidad por Kolmogorov-Smirnov para '{variable}'\")\n",
    "\n",
    "    # Kolmogorov-Smirnov (KS) test\n",
    "    ks_stat, ks_p = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data)))\n",
    "    print(f\" Estadístico = {ks_stat:.4f}, p-valor = {ks_p:.4f}\")\n",
    "\n",
    "def test_normalitySW(data, variable): # Prueba de Normalizas Shapiro-Wilks \n",
    "    \"\"\"\n",
    "    data: arreglo de datos a evaluar la normalidad\n",
    "    variable: string con el nombre de la variable \n",
    "    \"\"\"\n",
    "    print(f\"\\n Análisis de normalidad por Shapiro-Wilk para '{variable}'\")\n",
    "    # Shapiro-Wilk test\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(data)\n",
    "    print(f\"Estadístico = {shapiro_stat:.4f}, p-valor = {shapiro_p:.4f}\")\n",
    "    \n",
    "def random_test(residuos):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    residuos : Array\n",
    "        DESCRIPTION: Residuos del ANOVA \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    _, p_runs = runstest_1samp(residuos, correction=True)\n",
    "\n",
    "    print(f\"Prueba de Runs: p-valor={p_runs}\")\n",
    "    \n",
    "def test_homogeneityL(var1, var2, name1, name2): # Prueba de levene\n",
    "    \"\"\"\n",
    "    var1 y var2: variables a las que se corroborará homocedasticidad \n",
    "    name1 y name2: strings con el nnombre de las variables\n",
    "    \"\"\"\n",
    "    print(f\"\\n Análisis de homocedasticidad entre '{name1}' y '{name2}'\")\n",
    "\n",
    "    # Prueba de Levene (no asume normalidad)\n",
    "    levene_stat, levene_p = stats.levene(var1, var2)\n",
    "    print(f\"Levene test: Estadístico = {levene_stat:.4f}, p-valor = {levene_p:.4f}\")\n",
    "\n",
    "def t_test_one(data,mu,variable): #Prueba T para una muestra\n",
    "    \"\"\"\n",
    "    data: arreglo de datos a comparar\n",
    "    mu: media poblacional o valor de referencia \n",
    "    variable: string con el nombre de la variable que se está comparando\n",
    "    \"\"\"\n",
    "    print(f\"Prueba T para una sola muestra para {variable}\")\n",
    "    t_stat, p_value = stats.ttest_1samp(data, mu)\n",
    "    print(f\"Estadístico = {t_stat:.4f}, valor_p = {p_value:.4f}\")\n",
    "    \n",
    "def box_cox(data): #transformación depotencia   \n",
    "\n",
    "    transformed_data, lambda_opt = stats.boxcox(data)\n",
    "    return transformed_data, lambda_opt\n",
    "\n",
    "def tukey(respuesta,factor, alfa,n_factor):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    respuesta : Array\n",
    "        DESCRIPTION. Array con los datos de la variable respuesta\n",
    "    factor : Array\n",
    "        DESCRIPTION.Array con los niveles del factor \n",
    "    alfa : Float\n",
    "        DESCRIPTION. Valor alfa de comparación \n",
    "    n_factor : String\n",
    "        DESCRIPTION. Nombre del factor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    tukey = pairwise_tukeyhsd(respuesta, factor, alpha=alfa)\n",
    "    print(f\"Prueba Tukey para el factor {n_factor}\")\n",
    "    print(tukey)\n",
    "    \n",
    "def kruskal_W(df,Respuesta,Factor):\n",
    "    \"\"\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Data_Frame\n",
    "        DESCRIPTION. estructura con los datos del experimento\n",
    "    Respuesta : String\n",
    "        DESCRIPTION. nombre de la variable respuesta, key del dataframe\n",
    "    Factor : String\n",
    "        DESCRIPTION. nombre del factor, key del dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    grupos_B = [df[Respuesta][df[Factor] == nivel] for nivel in df[Factor].unique()]\n",
    "    stat_B, p_B = stats.kruskal(*grupos_B)\n",
    "    print(f\"Kruskal-Wallis para {Factor}: H = {stat_B:.4f}, p = {p_B:.4f}\")\n",
    "    \n",
    "    \n",
    "def kruskal_interaccion(df,Respuesta,Factor1,Factor2):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Data_Frame\n",
    "        DESCRIPTION. estructura con los datos del experimento\n",
    "    Respuesta : String\n",
    "        DESCRIPTION. nombre de la variable respuesta, key del dataframe\n",
    "    Factor1 : String\n",
    "        DESCRIPTION. nombre del factor1, key del dataframe\n",
    "    Factor2 : String\n",
    "        DESCRIPTION.nombre del factor12, key del dataframe\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    df['interaccion'] = df[Factor1].astype(str) + \"_\" + df[Factor2].astype(str) # se genera una columana con las combinaciones entre factores\n",
    "\n",
    "    grupos_interaccion = [df[Respuesta][df['interaccion'] == nivel] for nivel in df['interaccion'].unique()]\n",
    "    stat_int, p_int = stats.kruskal(*grupos_interaccion)\n",
    "    print(f\"Kruskal-Wallis para la interacción {Factor1}x{Factor2} p = {p_int:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d7254fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aveOralM      0\n",
      "Gender        0\n",
      "Age           0\n",
      "Ethnicity     0\n",
      "T_atm         0\n",
      "Humidity      0\n",
      "Cosmetics    29\n",
      "Distance      2\n",
      "Max1R13       0\n",
      "Max1L13       0\n",
      "T_Max         0\n",
      "TF_HCC        0\n",
      "dtype: int64\n",
      "\n",
      "moda de cosmeticos: 0    No\n",
      "Name: Cosmetics, dtype: object\n",
      "mode de cosmeticos imputando con la moda: 0    No\n",
      "Name: Cosmetics, dtype: object\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1020 entries, 0 to 1019\n",
      "Data columns (total 12 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   aveOralM   1020 non-null   float64\n",
      " 1   Gender     1020 non-null   object \n",
      " 2   Age        1020 non-null   object \n",
      " 3   Ethnicity  1020 non-null   object \n",
      " 4   T_atm      1020 non-null   float64\n",
      " 5   Humidity   1020 non-null   float64\n",
      " 6   Cosmetics  1020 non-null   object \n",
      " 7   Distance   1018 non-null   float64\n",
      " 8   Max1R13    1020 non-null   float64\n",
      " 9   Max1L13    1020 non-null   float64\n",
      " 10  T_Max      1020 non-null   float64\n",
      " 11  TF_HCC     1020 non-null   float64\n",
      "dtypes: float64(8), object(4)\n",
      "memory usage: 95.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(\"Proyecto 2/FLIR_groups1and2.csv\", sep=\";\" , header=2))[['Max1R13_1', 'Max1R13_2', 'Max1R13_3', 'Max1R13_4', \n",
    "        'Max1L13_1', 'Max1L13_2', 'Max1L13_3', 'Max1L13_4',\n",
    "        'T_Max1', 'T_Max2', 'T_Max3', 'T_Max4',\n",
    "        'T_FHCC1', 'T_FHCC2', 'T_FHCC3', 'T_FHCC4',\n",
    "        'aveOralM', 'Gender', 'Age', 'Ethnicity', 'T_atm', 'Humidity', 'Cosmetics','Distance']].copy() #cargamos el dataframe\n",
    "\n",
    "\n",
    "#creamos la nueva columna con el valor promediado de Max1R13 y eliminamos las demás\n",
    "df['Max1R13'] = df[['Max1R13_1', 'Max1R13_2', 'Max1R13_3', 'Max1R13_4']].mean(axis=1, skipna=True).astype(float)\n",
    "df.drop(columns=['Max1R13_1', 'Max1R13_2', 'Max1R13_3', 'Max1R13_4'],inplace=True) \n",
    "\n",
    "#creamos la nueva columna con el valor promediado de Max1L13 y eliminamos las demás\n",
    "df['Max1L13'] = df[['Max1L13_1', 'Max1L13_2', 'Max1L13_3', 'Max1L13_4']].mean(axis=1, skipna=True).astype(float)\n",
    "df.drop(columns=['Max1L13_1', 'Max1L13_2', 'Max1L13_3', 'Max1L13_4'],inplace=True)\n",
    "\n",
    "#creamos la nueva columna con el valor promediado de T_Max y eliminamos las demás\n",
    "df['T_Max'] = df[['T_Max1', 'T_Max2', 'T_Max3', 'T_Max4']].mean(axis=1, skipna=True).astype(float)\n",
    "df.drop(columns=['T_Max1', 'T_Max2', 'T_Max3', 'T_Max4'],inplace=True)\n",
    "\n",
    "#creamos la nueva columna con el valor promediado de TF_HCC y eliminamos las demás\n",
    "df['TF_HCC'] = df[['T_FHCC1', 'T_FHCC2', 'T_FHCC3', 'T_FHCC4']].mean(axis=1, skipna=True).astype(float)\n",
    "df.drop(columns=['T_FHCC1', 'T_FHCC2', 'T_FHCC3', 'T_FHCC4'],inplace=True)\n",
    "\n",
    "\n",
    "print(df.isnull().sum()) #Corroboramos si hay datos nulos\n",
    "\n",
    "#Veamos el comportamiento de los valores nulos de Cosmetics y como podemos tratarlos\n",
    "\n",
    "        #Primero pasamos los datos a una string pues son categoricos, para poder tratarlos como categoricos \n",
    "\n",
    "df[\"Cosmetics\"] = df[\"Cosmetics\"].map({0.0: \"No\", 1.0: \"Sí\"})\n",
    "\n",
    "print(f\"\\nmoda de cosmeticos: {df['Cosmetics'].mode()}\")\n",
    "\n",
    "b=df['Cosmetics'].fillna(df[\"Cosmetics\"].mode())\n",
    "print(f\"mode de cosmeticos imputando con la moda: {b.mode()}\\n\")\n",
    "\n",
    "#procedemos a imputar los valores nulos con la mediana\n",
    "\n",
    "df[\"Cosmetics\"] = df[\"Cosmetics\"].fillna(\"No\")\n",
    "\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
